/**
 * HTMF Neural Network Training
 *
 * This trains a policy and value network for the HTMF game using training data
 * generated by the selfplay MCTS system.
 *
 * The neural network architecture:
 * - Input: 8 channels x 60 cells = 480 features
 * - Hidden layers: 256 -> 128 -> 64
 * - Output heads:
 *   - Policy head (drafting): 60 values (one per cell for placement)
 *   - Policy head (movement): 3600 values (60 src x 60 dst)
 *   - Value head: 1 value (win probability)
 */

import * as fs from "fs";
import * as readline from "readline";

// Constants
const NUM_CELLS = 60;
const NUM_FEATURES = 8 * NUM_CELLS; // 480
const DRAFTING_POLICY_SIZE = NUM_CELLS; // 60
const MOVEMENT_POLICY_SIZE = NUM_CELLS * NUM_CELLS; // 3600

// Training sample structure matching Rust output
interface TrainingSample {
  features: number[];
  policy: number[];
  value: number;
  player: number;
  is_drafting: boolean;
}

// Simple matrix operations
class Matrix {
  data: Float32Array;
  rows: number;
  cols: number;

  constructor(rows: number, cols: number, data?: Float32Array) {
    this.rows = rows;
    this.cols = cols;
    this.data = data ?? new Float32Array(rows * cols);
  }

  static zeros(rows: number, cols: number): Matrix {
    return new Matrix(rows, cols);
  }

  static random(rows: number, cols: number, scale: number = 0.1): Matrix {
    const m = new Matrix(rows, cols);
    for (let i = 0; i < m.data.length; i++) {
      m.data[i] = (Math.random() * 2 - 1) * scale;
    }
    return m;
  }

  // Xavier/Glorot initialization
  static xavier(rows: number, cols: number): Matrix {
    const scale = Math.sqrt(2.0 / (rows + cols));
    return Matrix.random(rows, cols, scale);
  }

  get(row: number, col: number): number {
    return this.data[row * this.cols + col];
  }

  set(row: number, col: number, value: number): void {
    this.data[row * this.cols + col] = value;
  }

  clone(): Matrix {
    return new Matrix(this.rows, this.cols, new Float32Array(this.data));
  }
}

// Vector (1D array wrapper)
class Vector {
  data: Float32Array;

  constructor(size: number, data?: Float32Array) {
    this.data = data ?? new Float32Array(size);
  }

  get length(): number {
    return this.data.length;
  }

  static zeros(size: number): Vector {
    return new Vector(size);
  }

  static random(size: number, scale: number = 0.1): Vector {
    const v = new Vector(size);
    for (let i = 0; i < v.data.length; i++) {
      v.data[i] = (Math.random() * 2 - 1) * scale;
    }
    return v;
  }

  clone(): Vector {
    return new Vector(this.length, new Float32Array(this.data));
  }
}

// Dense layer
class DenseLayer {
  weights: Matrix;
  bias: Vector;

  // Gradients
  dWeights: Matrix;
  dBias: Vector;

  // Adam optimizer state
  mWeights: Matrix;
  vWeights: Matrix;
  mBias: Vector;
  vBias: Vector;

  // Cached input for backprop
  lastInput: Vector | null = null;

  constructor(inputSize: number, outputSize: number) {
    this.weights = Matrix.xavier(outputSize, inputSize);
    this.bias = Vector.zeros(outputSize);

    this.dWeights = Matrix.zeros(outputSize, inputSize);
    this.dBias = Vector.zeros(outputSize);

    // Adam state
    this.mWeights = Matrix.zeros(outputSize, inputSize);
    this.vWeights = Matrix.zeros(outputSize, inputSize);
    this.mBias = Vector.zeros(outputSize);
    this.vBias = Vector.zeros(outputSize);
  }

  forward(input: Vector): Vector {
    this.lastInput = input;
    const output = new Vector(this.weights.rows);
    for (let i = 0; i < this.weights.rows; i++) {
      let sum = this.bias.data[i];
      for (let j = 0; j < this.weights.cols; j++) {
        sum += this.weights.get(i, j) * input.data[j];
      }
      output.data[i] = sum;
    }
    return output;
  }

  backward(dOutput: Vector): Vector {
    const input = this.lastInput!;
    const dInput = new Vector(this.weights.cols);

    // Compute gradients
    for (let i = 0; i < this.weights.rows; i++) {
      this.dBias.data[i] += dOutput.data[i];
      for (let j = 0; j < this.weights.cols; j++) {
        this.dWeights.set(
          i,
          j,
          this.dWeights.get(i, j) + dOutput.data[i] * input.data[j]
        );
        dInput.data[j] += this.weights.get(i, j) * dOutput.data[i];
      }
    }

    return dInput;
  }

  zeroGrad(): void {
    this.dWeights.data.fill(0);
    this.dBias.data.fill(0);
  }

  // Adam optimizer step
  step(
    lr: number,
    beta1: number = 0.9,
    beta2: number = 0.999,
    epsilon: number = 1e-8,
    t: number = 1
  ): void {
    const biasCorrection1 = 1 - Math.pow(beta1, t);
    const biasCorrection2 = 1 - Math.pow(beta2, t);

    // Update weights
    for (let i = 0; i < this.weights.data.length; i++) {
      this.mWeights.data[i] =
        beta1 * this.mWeights.data[i] + (1 - beta1) * this.dWeights.data[i];
      this.vWeights.data[i] =
        beta2 * this.vWeights.data[i] +
        (1 - beta2) * this.dWeights.data[i] * this.dWeights.data[i];

      const mHat = this.mWeights.data[i] / biasCorrection1;
      const vHat = this.vWeights.data[i] / biasCorrection2;

      this.weights.data[i] -= (lr * mHat) / (Math.sqrt(vHat) + epsilon);
    }

    // Update bias
    for (let i = 0; i < this.bias.data.length; i++) {
      this.mBias.data[i] =
        beta1 * this.mBias.data[i] + (1 - beta1) * this.dBias.data[i];
      this.vBias.data[i] =
        beta2 * this.vBias.data[i] +
        (1 - beta2) * this.dBias.data[i] * this.dBias.data[i];

      const mHat = this.mBias.data[i] / biasCorrection1;
      const vHat = this.vBias.data[i] / biasCorrection2;

      this.bias.data[i] -= (lr * mHat) / (Math.sqrt(vHat) + epsilon);
    }
  }
}

// ReLU activation
function relu(v: Vector): Vector {
  const result = new Vector(v.length);
  for (let i = 0; i < v.length; i++) {
    result.data[i] = Math.max(0, v.data[i]);
  }
  return result;
}

function reluBackward(v: Vector, dOutput: Vector): Vector {
  const result = new Vector(v.length);
  for (let i = 0; i < v.length; i++) {
    result.data[i] = v.data[i] > 0 ? dOutput.data[i] : 0;
  }
  return result;
}

// Softmax with numerical stability
function softmax(v: Vector): Vector {
  const result = new Vector(v.length);
  let maxVal = -Infinity;
  for (let i = 0; i < v.length; i++) {
    if (v.data[i] > maxVal) maxVal = v.data[i];
  }
  let sum = 0;
  for (let i = 0; i < v.length; i++) {
    result.data[i] = Math.exp(v.data[i] - maxVal);
    sum += result.data[i];
  }
  for (let i = 0; i < v.length; i++) {
    result.data[i] /= sum;
  }
  return result;
}

// Sigmoid
function sigmoid(x: number): number {
  return 1 / (1 + Math.exp(-x));
}

// Neural network for HTMF
class HTMFNetwork {
  // Shared trunk
  layer1: DenseLayer;
  layer2: DenseLayer;
  layer3: DenseLayer;

  // Policy heads
  draftingPolicyHead: DenseLayer;
  movementPolicyHead: DenseLayer;

  // Value head
  valueHead: DenseLayer;

  // Cached activations for backprop
  private h1Pre: Vector | null = null;
  private h1: Vector | null = null;
  private h2Pre: Vector | null = null;
  private h2: Vector | null = null;
  private h3Pre: Vector | null = null;
  private h3: Vector | null = null;

  constructor() {
    // Shared layers
    this.layer1 = new DenseLayer(NUM_FEATURES, 256);
    this.layer2 = new DenseLayer(256, 128);
    this.layer3 = new DenseLayer(128, 64);

    // Policy heads
    this.draftingPolicyHead = new DenseLayer(64, DRAFTING_POLICY_SIZE);
    this.movementPolicyHead = new DenseLayer(64, MOVEMENT_POLICY_SIZE);

    // Value head
    this.valueHead = new DenseLayer(64, 1);
  }

  forward(
    features: Vector,
    isDrafting: boolean
  ): { policy: Vector; value: number } {
    // Forward through trunk
    this.h1Pre = this.layer1.forward(features);
    this.h1 = relu(this.h1Pre);

    this.h2Pre = this.layer2.forward(this.h1);
    this.h2 = relu(this.h2Pre);

    this.h3Pre = this.layer3.forward(this.h2);
    this.h3 = relu(this.h3Pre);

    // Policy head
    const policyLogits = isDrafting
      ? this.draftingPolicyHead.forward(this.h3)
      : this.movementPolicyHead.forward(this.h3);
    const policy = softmax(policyLogits);

    // Value head
    const valueLogit = this.valueHead.forward(this.h3);
    const value = sigmoid(valueLogit.data[0]);

    return { policy, value };
  }

  backward(
    targetPolicy: Vector,
    targetValue: number,
    predictedPolicy: Vector,
    predictedValue: number,
    isDrafting: boolean
  ): { policyLoss: number; valueLoss: number } {
    // Policy loss gradient (cross-entropy derivative)
    const dPolicy = new Vector(predictedPolicy.length);
    let policyLoss = 0;
    for (let i = 0; i < predictedPolicy.length; i++) {
      const p = Math.max(predictedPolicy.data[i], 1e-7);
      if (targetPolicy.data[i] > 0) {
        policyLoss -= targetPolicy.data[i] * Math.log(p);
      }
      dPolicy.data[i] = predictedPolicy.data[i] - targetPolicy.data[i];
    }

    // Value loss gradient (MSE derivative)
    const valueLoss = Math.pow(predictedValue - targetValue, 2);
    const dValue = new Vector(1);
    dValue.data[0] =
      2 *
      (predictedValue - targetValue) *
      predictedValue *
      (1 - predictedValue);

    // Backprop through heads
    const dH3FromPolicy = isDrafting
      ? this.draftingPolicyHead.backward(dPolicy)
      : this.movementPolicyHead.backward(dPolicy);
    const dH3FromValue = this.valueHead.backward(dValue);

    // Combine gradients
    const dH3 = new Vector(dH3FromPolicy.length);
    for (let i = 0; i < dH3.length; i++) {
      dH3.data[i] = dH3FromPolicy.data[i] + dH3FromValue.data[i];
    }

    // Backprop through trunk
    const dH3Pre = reluBackward(this.h3Pre!, dH3);
    const dH2 = this.layer3.backward(dH3Pre);

    const dH2Pre = reluBackward(this.h2Pre!, dH2);
    const dH1 = this.layer2.backward(dH2Pre);

    const dH1Pre = reluBackward(this.h1Pre!, dH1);
    this.layer1.backward(dH1Pre);

    return { policyLoss, valueLoss };
  }

  zeroGrad(): void {
    this.layer1.zeroGrad();
    this.layer2.zeroGrad();
    this.layer3.zeroGrad();
    this.draftingPolicyHead.zeroGrad();
    this.movementPolicyHead.zeroGrad();
    this.valueHead.zeroGrad();
  }

  step(lr: number, t: number): void {
    this.layer1.step(lr, 0.9, 0.999, 1e-8, t);
    this.layer2.step(lr, 0.9, 0.999, 1e-8, t);
    this.layer3.step(lr, 0.9, 0.999, 1e-8, t);
    this.draftingPolicyHead.step(lr, 0.9, 0.999, 1e-8, t);
    this.movementPolicyHead.step(lr, 0.9, 0.999, 1e-8, t);
    this.valueHead.step(lr, 0.9, 0.999, 1e-8, t);
  }

  // Save weights to JSON
  save(path: string): void {
    const data = {
      layer1: {
        weights: Array.from(this.layer1.weights.data),
        bias: Array.from(this.layer1.bias.data),
      },
      layer2: {
        weights: Array.from(this.layer2.weights.data),
        bias: Array.from(this.layer2.bias.data),
      },
      layer3: {
        weights: Array.from(this.layer3.weights.data),
        bias: Array.from(this.layer3.bias.data),
      },
      draftingPolicyHead: {
        weights: Array.from(this.draftingPolicyHead.weights.data),
        bias: Array.from(this.draftingPolicyHead.bias.data),
      },
      movementPolicyHead: {
        weights: Array.from(this.movementPolicyHead.weights.data),
        bias: Array.from(this.movementPolicyHead.bias.data),
      },
      valueHead: {
        weights: Array.from(this.valueHead.weights.data),
        bias: Array.from(this.valueHead.bias.data),
      },
    };
    fs.writeFileSync(path, JSON.stringify(data));
  }

  // Load weights from JSON
  load(path: string): void {
    const data = JSON.parse(fs.readFileSync(path, "utf-8"));

    this.layer1.weights.data = new Float32Array(data.layer1.weights);
    this.layer1.bias.data = new Float32Array(data.layer1.bias);

    this.layer2.weights.data = new Float32Array(data.layer2.weights);
    this.layer2.bias.data = new Float32Array(data.layer2.bias);

    this.layer3.weights.data = new Float32Array(data.layer3.weights);
    this.layer3.bias.data = new Float32Array(data.layer3.bias);

    this.draftingPolicyHead.weights.data = new Float32Array(
      data.draftingPolicyHead.weights
    );
    this.draftingPolicyHead.bias.data = new Float32Array(
      data.draftingPolicyHead.bias
    );

    this.movementPolicyHead.weights.data = new Float32Array(
      data.movementPolicyHead.weights
    );
    this.movementPolicyHead.bias.data = new Float32Array(
      data.movementPolicyHead.bias
    );

    this.valueHead.weights.data = new Float32Array(data.valueHead.weights);
    this.valueHead.bias.data = new Float32Array(data.valueHead.bias);
  }
}

// Load training data from JSONL file
async function loadTrainingData(path: string): Promise<TrainingSample[]> {
  const samples: TrainingSample[] = [];

  const fileStream = fs.createReadStream(path);
  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity,
  });

  for await (const line of rl) {
    if (line.trim()) {
      try {
        samples.push(JSON.parse(line));
      } catch (e) {
        console.error("Failed to parse line:", line.substring(0, 100));
      }
    }
  }

  return samples;
}

// Shuffle array in place
function shuffle<T>(array: T[]): void {
  for (let i = array.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [array[i], array[j]] = [array[j], array[i]];
  }
}

// Main training loop
async function train() {
  const dataPath = process.argv[2] || "./artifacts/training_data.jsonl";
  const epochs = parseInt(process.argv[3] || "10");
  const batchSize = parseInt(process.argv[4] || "32");
  const learningRate = parseFloat(process.argv[5] || "0.001");

  console.log(`Loading training data from ${dataPath}...`);
  const samples = await loadTrainingData(dataPath);

  if (samples.length === 0) {
    console.error("No training samples found!");
    console.log("Generate training data first with:");
    console.log(
      "  cargo run --release -p selfplay > artifacts/training_data.jsonl"
    );
    process.exit(1);
  }

  // Split into drafting and movement samples
  const draftingSamples = samples.filter((s) => s.is_drafting);
  const movementSamples = samples.filter((s) => !s.is_drafting);

  console.log(`Loaded ${samples.length} samples:`);
  console.log(`  - Drafting: ${draftingSamples.length}`);
  console.log(`  - Movement: ${movementSamples.length}`);
  console.log(`Training for ${epochs} epochs with batch size ${batchSize}`);
  console.log(`Learning rate: ${learningRate}`);

  const network = new HTMFNetwork();
  let globalStep = 0;

  for (let epoch = 0; epoch < epochs; epoch++) {
    shuffle(samples);

    let totalPolicyLoss = 0;
    let totalValueLoss = 0;
    let numBatches = 0;

    for (let i = 0; i < samples.length; i += batchSize) {
      const batch = samples.slice(i, Math.min(i + batchSize, samples.length));
      network.zeroGrad();

      let batchPolicyLoss = 0;
      let batchValueLoss = 0;

      for (const sample of batch) {
        const features = new Vector(
          sample.features.length,
          new Float32Array(sample.features)
        );
        const targetPolicy = new Vector(
          sample.policy.length,
          new Float32Array(sample.policy)
        );

        const { policy, value } = network.forward(features, sample.is_drafting);
        const { policyLoss, valueLoss } = network.backward(
          targetPolicy,
          sample.value,
          policy,
          value,
          sample.is_drafting
        );

        batchPolicyLoss += policyLoss;
        batchValueLoss += valueLoss;
      }

      // Average gradients over batch
      const scale = 1 / batch.length;
      for (const layer of [
        network.layer1,
        network.layer2,
        network.layer3,
        network.draftingPolicyHead,
        network.movementPolicyHead,
        network.valueHead,
      ]) {
        for (let j = 0; j < layer.dWeights.data.length; j++) {
          layer.dWeights.data[j] *= scale;
        }
        for (let j = 0; j < layer.dBias.data.length; j++) {
          layer.dBias.data[j] *= scale;
        }
      }

      globalStep++;
      network.step(learningRate, globalStep);

      totalPolicyLoss += batchPolicyLoss / batch.length;
      totalValueLoss += batchValueLoss / batch.length;
      numBatches++;
    }

    const avgPolicyLoss = totalPolicyLoss / numBatches;
    const avgValueLoss = totalValueLoss / numBatches;

    console.log(
      `Epoch ${epoch + 1}/${epochs}: Policy Loss = ${avgPolicyLoss.toFixed(
        4
      )}, Value Loss = ${avgValueLoss.toFixed(4)}`
    );

    // Save checkpoint every epoch
    network.save(`./artifacts/epochs/model_epoch_${epoch + 1}.json`);
  }

  // Save final model
  network.save("./artifacts/model_final.json");
  console.log("Training complete! Model saved to artifacts/model_final.json");

  // Validate on a few samples
  console.log("\nValidation on first 5 samples:");
  for (let i = 0; i < Math.min(5, samples.length); i++) {
    const sample = samples[i];
    const features = new Vector(
      sample.features.length,
      new Float32Array(sample.features)
    );
    const { policy, value } = network.forward(features, sample.is_drafting);

    // Find top predicted move
    let topIdx = 0;
    for (let j = 1; j < policy.length; j++) {
      if (policy.data[j] > policy.data[topIdx]) topIdx = j;
    }

    // Find top target move
    let targetTopIdx = 0;
    for (let j = 1; j < sample.policy.length; j++) {
      if (sample.policy[j] > sample.policy[targetTopIdx]) targetTopIdx = j;
    }

    console.log(
      `  Sample ${i + 1}: Predicted value = ${value.toFixed(
        3
      )}, Target value = ${
        sample.value
      }, Top move: pred=${topIdx}, target=${targetTopIdx}`
    );
  }
}

train().catch(console.error);
